Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Zakaria2020,
abstract = {With the rapid surge of renewable energy integrations into the electrical grid, the main questions remain; how do we manage and operate optimally these surges of fluctuating resources? However, vast optimization approaches in renewable energy applications have been widely used hitherto to aid decision-makings in mitigating the limitations of computations. This paper comprehensively reviews the generic steps of stochastic optimizations in renewable energy applications, from the modelling of the uncertainties and sampling of relevant information, respectively. Furthermore, the benefits and drawbacks of the stochastic optimization methods are highlighted. Moreover, notable optimization methods pertaining to the steps of stochastic optimizations are highlighted. The aim of the paper is to introduce the recent advancements and notable stochastic methods and trending of the methods going into the future of renewable energy applications. Relevant future research areas are identified to support the transition of stochastic optimizations from the traditional deterministic approaches. We concluded based on the surveyed literatures that the stochastic optimization methods almost always outperform the deterministic optimization methods in terms of social, technical, and economic aspects of renewable energy systems. Thus, this review will catalyse the effort in advancing the research of stochastic optimization methods within the scopes of renewable energy applications.},
author = {Zakaria, A. and Ismail, Firas B. and Lipu, M. S.Hossain and Hannan, M. A.},
doi = {10.1016/j.renene.2019.07.081},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0960148119311012-main.pdf:pdf},
issn = {18790682},
journal = {Renewable Energy},
keywords = {Renewable energy applications,Scenario generations,Stochastic optimizations,Uncertainty model},
pages = {1543--1571},
publisher = {Elsevier Ltd},
title = {{Uncertainty models for stochastic optimization in renewable energy applications}},
url = {https://doi.org/10.1016/j.renene.2019.07.081},
volume = {145},
year = {2020}
}

@article{Drake2019,
	title={Recent advances in selection hyper-heuristics},
	author={Drake, John H and Kheiri, Ahmed and {\"O}zcan, Ender and Burke, Edmund K},
	journal={European Journal of Operational Research},
	year={2019},
	publisher={Elsevier}
}

@article{Chowdhury2019,
abstract = {We consider black box optimization of an unknown function in the nonparametric Gaussian process setting when the noise in the observed function values can be heavy tailed. This is in contrast to existing literature that typically assumes sub-Gaussian noise distributions for queries. Under the assumption that the unknown function belongs to the Reproducing Kernel Hilbert Space (RKHS) induced by a kernel, we first show that an adaptation of the well-known GP-UCB algorithm with reward truncation enjoys sublinear {\$}\backslashtilde{\{}O{\}}(T{\^{}}{\{}\backslashfrac{\{}2 + \backslashalpha{\}}{\{}2(1+\backslashalpha){\}}{\}}){\$} regret even with only the {\$}(1+\backslashalpha){\$}-th moments, {\$}\backslashalpha \backslashin (0,1]{\$}, of the reward distribution being bounded ({\$}\backslashtilde{\{}O{\}}{\$} hides logarithmic factors). However, for the common squared exponential (SE) and Mat$\backslash$'{\{}e{\}}rn kernels, this is seen to be significantly larger than a fundamental {\$}\backslashOmega(T{\^{}}{\{}\backslashfrac{\{}1{\}}{\{}1+\backslashalpha{\}}{\}}){\$} lower bound on regret. We resolve this gap by developing novel Bayesian optimization algorithms, based on kernel approximation techniques, with regret bounds matching the lower bound in order for the SE kernel. We numerically benchmark the algorithms on environments based on both synthetic models and real-world data sets.},
archivePrefix = {arXiv},
arxivId = {1909.07040},
author = {Chowdhury, Sayak Ray and Gopalan, Aditya},
eprint = {1909.07040},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9531-bayesian-optimization-under-heavy-tailed-payoffs.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Bayesian Optimization under Heavy-tailed Payoffs}},
url = {http://arxiv.org/abs/1909.07040},
year = {2019}
}
@article{Awasthi2019,
abstract = {We study the design of computationally efficient algorithms with provable guarantees, that are robust to adversarial (test time) perturbations. While there has been an proliferation of recent work on this topic due to its connections to test time robustness of deep networks, there is limited theoretical understanding of several basic questions like (i) when and how can one design provably robust learning algorithms? (ii) what is the price of achieving robustness to adversarial examples in a computationally efficient manner? The main contribution of this work is to exhibit a strong connection between achieving robustness to adversarial examples, and a rich class of polynomial optimization problems, thereby making progress on the above questions. In particular, we leverage this connection to (a) design computationally efficient robust algorithms with provable guarantees for a large class of hypothesis, namely linear classifiers and degree-2 polynomial threshold functions (PTFs), (b) give a precise characterization of the price of achieving robustness in a computationally efficient manner for these classes, (c) design efficient algorithms to certify robustness and generate adversarial attacks in a principled manner for 2-layer neural networks. We empirically demonstrate the effectiveness of these attacks on real data.},
archivePrefix = {arXiv},
arxivId = {1911.04681},
author = {Awasthi, Pranjal and Dutta, Abhratanu and Vijayaraghavan, Aravindan},
eprint = {1911.04681},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9526-on-robustness-to-adversarial-examples-and-polynomial-optimization.pdf:pdf},
number = {NeurIPS},
title = {{On Robustness to Adversarial Examples and Polynomial Optimization}},
url = {http://arxiv.org/abs/1911.04681},
year = {2019}
}
@article{Yang2009,
archivePrefix = {arXiv},
arxivId = {arXiv:1003.1594v1},
author = {Yang, Xin-she and Cb, Cambridge and Deb, Suash},
eprint = {arXiv:1003.1594v1},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1003.1594.pdf:pdf},
keywords = {cs,cuckoo search},
mendeley-tags = {cs,cuckoo search},
title = {{Cuckoo Search via L{\'{e}}vy Flights}},
year = {2009}
}
@article{Huyer1998,
author = {Huyer, Waltraud and Neumaier, Arnold},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/mcs(1).pdf:pdf},
keywords = {bound constraints,coordinate,global optimization,local optimization,mcs,multilevel coordinate search},
mendeley-tags = {mcs,multilevel coordinate search},
number = {1995},
pages = {1--28},
title = {{Global Optimization by Multilevel Coordinate Search}},
year = {1998}
}
@article{Wilson2019,
abstract = {We present a family of algorithms, called descent algorithms, for optimizing convex and non-convex functions. We also introduce a new first-order algorithm, called rescaled gradient descent (RGD), and show that RGD achieves a faster convergence rate than gradient descent provided the function is strongly smooth -- a natural generalization of the standard smoothness assumption on the objective function. When the objective function is convex, we present two novel frameworks for "accelerating" descent methods, one in the style of Nesterov and the other in the style of Monteiro and Svaiter, using a single Lyapunov. Rescaled gradient descent can be accelerated under the same strong smoothness assumption using both frameworks. We provide several examples of strongly smooth loss functions in machine learning and numerical experiments that verify our theoretical findings. We also present several extensions of our novel Lyapunov framework, including deriving optimal universal tensor methods and extending our framework to the coordinate setting.},
archivePrefix = {arXiv},
arxivId = {1902.08825},
author = {Wilson, Ashia and Mackey, Lester and Wibisono, Andre},
eprint = {1902.08825},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9508-accelerating-rescaled-gradient-descent-fast-optimization-of-smooth-functions.pdf:pdf},
number = {1},
pages = {1--11},
title = {{Accelerating Rescaled Gradient Descent: Fast Optimization of Smooth Functions}},
url = {http://arxiv.org/abs/1902.08825},
year = {2019}
}
@article{Yang2014,
abstract = {Cuckoo search (CS) is a relatively new algorithm, developed by Yang and Deb in 2009, and the same has been found to be efficient in solving global optimization problems. In this paper, we review the fundamental ideas of cuckoo search and the latest developments as well as its applications. We analyze the algorithm and gain insight into its search mechanisms and find out why it is efficient. We also discuss the essence of algorithms and its link to self-organizing systems, and finally, we propose some important topics for further research. {\textcopyright} 2013 Springer-Verlag London.},
archivePrefix = {arXiv},
arxivId = {1408.5316},
author = {Yang, Xin She and Deb, Suash},
doi = {10.1007/s00521-013-1367-1},
eprint = {1408.5316},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1408.5316.pdf:pdf},
issn = {09410643},
journal = {Neural Computing and Applications},
keywords = {Convergence,Cuckoo search,Metaheuristic,Nature-inspired algorithm,Swarm intelligence optimization,cs,cuckoo search},
mendeley-tags = {cs,cuckoo search},
number = {1},
pages = {169--174},
title = {{Cuckoo search: Recent advances and applications}},
volume = {24},
year = {2014}
}
@article{Duchi2012,
abstract = {By combining randomized smoothing techniques with accelerated gradient methods, we obtain convergence rates for stochastic optimization procedures, both in expectation and with high probability, that have optimal dependence on the variance of the gradient estimates. To the best of our knowledge, these are the first variance-based rates for non-smooth optimization. A combination of our techniques with recent work on decentralized optimization yields order-optimal parallel stochastic optimization algorithms. We give applications of our results to several statistical machine learning problems, providing experimental results (in the full version of the paper) demonstrating the effectiveness of our algorithms. {\textcopyright} 2012 IEEE.},
archivePrefix = {arXiv},
arxivId = {1103.4296},
author = {Duchi, John C. and Bartlett, Peter L. and Wainwright, Martin J.},
doi = {10.1109/CDC.2012.6426698},
eprint = {1103.4296},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/duchi11a.pdf:pdf},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
keywords = {adaptivity,online learning,stochastic convex optimization,subgradient methods},
pages = {5442--5444},
title = {{Randomized smoothing for (parallel) stochastic optimization}},
volume = {12},
year = {2012}
}
@article{Khare2013,
author = {Khare, Anula and Rangnekar, Saroj},
doi = {10.1016/j.asoc.2012.11.033},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S1568494612005170-main.pdf:pdf},
issn = {1568-4946},
journal = {Applied Soft Computing Journal},
keywords = {control,linearly decreasing inertia weight,particle swarm,particle swarm optimization,pso,pso parameters},
mendeley-tags = {particle swarm,pso},
number = {5},
pages = {2997--3006},
publisher = {Elsevier B.V.},
title = {{Review article A review of particle swarm optimization and its applications in Solar Photovoltaic system}},
url = {http://dx.doi.org/10.1016/j.asoc.2012.11.033},
volume = {13},
year = {2013}
}
@article{Rakshit2017,
abstract = {Noisy optimization is currently receiving increasing popularity for its widespread applications in engineering optimization problems, where the objective functions are often found to be contaminated with noisy sensory measurements. In absence of knowledge of the noise-statistics, discriminating better trial solutions from the rest becomes difficult in the “selection” step of an evolutionary optimization algorithm with noisy objective/s. This paper provides a thorough survey of the present state-of-the-art research on noisy evolutionary algorithms for both single and multi-objective optimization problems. This is undertaken by incorporating one or more of the five strategies in traditional evolutionary algorithms. The strategies include (i) fitness sampling of individual trial solution, (ii) fitness estimation of noisy samples, (iii) dynamic population sizing over the generations, (iv) adaptation of the evolutionary search strategy, and (v) modification in the selection strategy.},
author = {Rakshit, Pratyusha and Konar, Amit and Das, Swagatam},
doi = {10.1016/j.swevo.2016.09.002},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S221065021630308X-main(1).pdf:pdf},
issn = {22106502},
journal = {Swarm and Evolutionary Computation},
keywords = {Evolutionary optimization,Fitness estimation,Noise,Population sizing,Sampling,Selection,Uncertainty},
number = {May 2016},
pages = {18--45},
publisher = {Elsevier B.V.},
title = {{Noisy evolutionary optimization algorithms – A comprehensive survey}},
url = {http://dx.doi.org/10.1016/j.swevo.2016.09.002},
volume = {33},
year = {2017}
}
@phdthesis{Turan2020,
author = {Turan, Ozgur Taylan},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/Add.Grad.Work.pdf:pdf},
school = {TU Delft},
title = {{Reduced Order Model Base Creation with Bayesian Optimization}},
year = {2020}
}
@article{Li2017,
abstract = {Wind farm layout optimisation is a challenging real-world problem which requires the discovery of trade-off solutions considering a variety of conflicting criteria, such as minimisation of the land area usage and maximisation of energy production. However, due to the complexity of handling multiple objectives simultaneously, many approaches proposed in the literature often focus on the optimisation of a single objective when deciding the locations for a set of wind turbines spread across a given region. In this study, we tackle a multi-objective wind farm layout optimisation problem. Different from the previously proposed approaches, we are applying a high-level search method, known as selection hyper-heuristic to solve this problem. Selection hyper-heuristics mix and control a predefined set of low-level (meta)heuristics which operate on solutions. We test nine different selection hyper-heuristics including an online learning hyper-heuristic on a multi-objective wind farm layout optimisation problem. Our hyper-heuristic approaches manage three well-known multi-objective evolutionary algorithms as low-level metaheuristics. The empirical results indicate the success and potential of selection hyper-heuristics for solving this computationally difficult problem. We additionally explore other objectives in wind farm layout optimisation problems to gain a better understanding of the conflicting nature of those objectives.},
author = {Li, Wenwen and {\"{O}}zcan, Ender and John, Robert},
doi = {10.1016/j.renene.2016.12.022},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0960148116310709-main.pdf:pdf},
issn = {18790682},
journal = {Renewable Energy},
keywords = {Evolutionary algorithms,Hyper-heuristics,Layout design,Operation research,Optimisation,Wind farm},
pages = {473--482},
title = {{Multi-objective evolutionary algorithms and hyper-heuristics for wind farm layout optimisation}},
volume = {105},
year = {2017}
}
@article{Fang2018,
author = {Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/7349-spider-near-optimal-non-convex-optimization-via-stochastic-path-integrated-differential-estimator.pdf:pdf},
number = {NeurIPS},
pages = {1--11},
title = {{SPIDER : Near-Optimal Non-Convex Optimization via Stochastic Path Integrated Differential Estimator}},
volume = {1},
year = {2018}
}
@article{Zeiler2012,
abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
archivePrefix = {arXiv},
arxivId = {1212.5701},
author = {Zeiler, Matthew D.},
eprint = {1212.5701},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1212.5701.pdf:pdf},
title = {{ADADELTA: An Adaptive Learning Rate Method}},
url = {http://arxiv.org/abs/1212.5701},
year = {2012}
}
@article{DeFreitas2013,
author = {de Freitas, Nando},
doi = {10.14708/cm.v9i2.5542},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/l6.pdf:pdf},
issn = {2080-1211},
journal = {Commentationes Mathematicae},
title = {{Gaussian processes}},
year = {2013}
}
@article{Ozcan,
author = {{\"{O}}zcan, Ender and Bilgin, Burak and Korkmaz, Emin Erkan and Cad, İ},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/A{\_}comprehensive{\_}analysis{\_}of{\_}hyper-heuris.pdf:pdf},
title = {{A Comprehensive Analysis of Hyper-heuristics}},
year = {2006}
}
@article{Jackson2018,
author = {Jackson, Warren G and {\"{O}}zcan, Ender and John, Robert I},
doi = {10.1016/j.eswa.2018.05.006},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0957417418302835-main.pdf:pdf},
issn = {0957-4174},
journal = {Expert Systems With Applications},
keywords = {Combinatorial optimization,Parameter control,Stoch,combinatorial optimization},
pages = {131--151},
publisher = {Elsevier Ltd},
title = {{Move acceptance in local search metaheuristics for cross-domain search}},
url = {https://doi.org/10.1016/j.eswa.2018.05.006},
volume = {109},
year = {2018}
}
@article{Bessa2019,
abstract = {Designing future-proof materials goes beyond a quest for the best. The next generation of materials needs to be adaptive, multipurpose, and tunable. This is not possible by following the traditional experimentally guided trial-and-error process, as this limits the search for untapped regions of the solution space. Here, a computational data-driven approach is followed for exploring a new metamaterial concept and adapting it to different target properties, choice of base materials, length scales, and manufacturing processes. Guided by Bayesian machine learning, two designs are fabricated at different length scales that transform brittle polymers into lightweight, recoverable, and supercompressible metamaterials. The macroscale design is tuned for maximum compressibility, achieving strains beyond 94{\%} and recoverable strengths around 0.1 kPa, while the microscale design reaches recoverable strengths beyond 100 kPa and strains around 80{\%}. The data-driven code is available to facilitate future design and analysis of metamaterials and structures (https://github.com/mabessa/F3DAS).},
author = {Bessa, Miguel A. and Glowacki, Piotr and Houlder, Michael},
doi = {10.1002/adma.201904845},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/adma.201904845.pdf:pdf},
issn = {15214095},
journal = {Advanced Materials},
keywords = {additive manufacturing,data-driven design,deep learning,machine learning,optimization},
number = {48},
pages = {1--6},
title = {{Bayesian Machine Learning in Metamaterial Design: Fragile Becomes Supercompressible}},
volume = {31},
year = {2019}
}
@article{Rios2013,
abstract = {This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2,500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution. {\textcopyright} 2012 Springer Science+Business Media, LLC.},
annote = {Overall review paper of different derivative-free optimization techniques

Local search
- Nelder-Mead
- Generalized Pattern Search

Global search
- Lipschitzian
- MCS
-RSMs
- Efficient global optimization (EGO)
etc.},
author = {Rios, Luis Miguel and Sahinidis, Nikolaos V.},
doi = {10.1007/s10898-012-9951-y},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/Rios-Sahinidis2013{\_}Article{\_}Derivative-freeOptimizationARe.pdf:pdf},
issn = {09255001},
journal = {Journal of Global Optimization},
keywords = {Derivative-free algorithms,Direct search methods,Surrogate models,derivative free},
mendeley-tags = {derivative free},
number = {3},
pages = {1247--1293},
title = {{Derivative-free optimization: A review of algorithms and comparison of software implementations}},
volume = {56},
year = {2013}
}
@article{Thekumparampil2019,
abstract = {This paper studies first order methods for solving smooth minimax optimization problems {\$}\backslashmin{\_}x \backslashmax{\_}y g(x,y){\$} where {\$}g(\backslashcdot,\backslashcdot){\$} is smooth and {\$}g(x,\backslashcdot){\$} is concave for each {\$}x{\$}. In terms of {\$}g(\backslashcdot,y){\$}, we consider two settings -- strongly convex and nonconvex -- and improve upon the best known rates in both. For strongly-convex {\$}g(\backslashcdot, y),\backslash \backslashforall y{\$}, we propose a new algorithm combining Mirror-Prox and Nesterov's AGD, and show that it can find global optimum in {\$}\backslashtilde{\{}O{\}}(1/k{\^{}}2){\$} iterations, improving over current state-of-the-art rate of {\$}O(1/k){\$}. We use this result along with an inexact proximal point method to provide {\$}\backslashtilde{\{}O{\}}(1/k{\^{}}{\{}1/3{\}}){\$} rate for finding stationary points in the nonconvex setting where {\$}g(\backslashcdot, y){\$} can be nonconvex. This improves over current best-known rate of {\$}O(1/k{\^{}}{\{}1/5{\}}){\$}. Finally, we instantiate our result for finite nonconvex minimax problems, i.e., {\$}\backslashmin{\_}x \backslashmax{\_}{\{}1\backslashleq i\backslashleq m{\}} f{\_}i(x){\$}, with nonconvex {\$}f{\_}i(\backslashcdot){\$}, to obtain convergence rate of {\$}O(m(\backslashlog m){\^{}}{\{}3/2{\}}/k{\^{}}{\{}1/3{\}}){\$} total gradient evaluations for finding a stationary point.},
archivePrefix = {arXiv},
arxivId = {1907.01543},
author = {Thekumparampil, Kiran Koshy and Jain, Prateek and Netrapalli, Praneeth and Oh, Sewoong},
eprint = {1907.01543},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9430-efficient-algorithms-for-smooth-minimax-optimization.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Efficient Algorithms for Smooth Minimax Optimization}},
url = {http://arxiv.org/abs/1907.01543},
year = {2019}
}
@article{Padhye2012,
author = {Padhye, Nikhil and Deb, Kalyanmoy},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/k2012014.pdf:pdf},
keywords = {particle swarm,pso},
mendeley-tags = {particle swarm,pso},
title = {{Boundary Handling Approaches in Particle Swarm Optimization}},
year = {2012}
}
@article{Mitsos2008,
annote = {from plato.asu.edu/sub/tutorials.html},
author = {Mitsos, Alexander and Chachuat, Beno{\^{i}}t and Barton, Paul I.},
doi = {10.1017/cbo9780511691881.010},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/book.pdf:pdf},
isbn = {9780816910502},
journal = {AIChE Annual Meeting, Conference Proceedings},
keywords = {optimization decision tree},
mendeley-tags = {optimization decision tree},
title = {{Global optimization of algorithms}},
year = {2008}
}
@book{Onwubolu2004,
author = {Onwubolu, G C and Babu, B V},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/(Studies in Fuzziness and Soft Computing 141) Professor Godfrey C. Onwubolu, Professor B. V. Babu (auth.) - New Optimization Techn(2004).pdf:pdf},
isbn = {9783642057670},
publisher = {Springer-Verlag},
title = {{New Optimization Techniques in Engineering}},
year = {2004}
}
@article{Talwar2019,
abstract = {Two commonly arising computational tasks in Bayesian learning are Optimization (Maximum A Posteriori estimation) and Sampling (from the posterior distribution). In the convex case these two problems are efficiently reducible to each other. Recent work (Ma et al. 2019) shows that in the non-convex case, sampling can sometimes be provably faster. We present a simpler and stronger separation. We then compare sampling and optimization in more detail and show that they are provably incomparable: there are families of continuous functions for which optimization is easy but sampling is NP-hard, and vice versa. Further, we show function families that exhibit a sharp phase transition in the computational complexity of sampling, as one varies the natural temperature parameter. Our results draw on a connection to analogous separations in the discrete setting which are well-studied.},
archivePrefix = {arXiv},
arxivId = {1911.02074},
author = {Talwar, Kunal},
eprint = {1911.02074},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9639-computational-separations-between-sampling-and-optimization.pdf:pdf},
number = {NeurIPS},
title = {{Computational Separations between Sampling and Optimization}},
url = {http://arxiv.org/abs/1911.02074},
year = {2019}
}
@article{Brochu2010,
abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
archivePrefix = {arXiv},
arxivId = {1012.2599},
author = {Brochu, Eric and Cora, Vlad M. and de Freitas, Nando},
eprint = {1012.2599},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1012.2599.pdf:pdf},
title = {{A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning}},
url = {http://arxiv.org/abs/1012.2599},
year = {2010}
}
@article{Orvieto2018,
abstract = {We propose new continuous-time formulations for first-order stochastic optimization algorithms such as mini-batch gradient descent and variance-reduced methods. We exploit these continuous-time models, together with simple Lyapunov analysis as well as tools from stochastic calculus, in order to derive convergence bounds for various types of non-convex functions. Guided by such analysis, we show that the same Lyapunov arguments hold in discrete-time, leading to matching rates. In addition, we use these models and Ito calculus to infer novel insights on the dynamics of SGD, proving that a decreasing learning rate acts as time warping or, equivalently, as landscape stretching.},
archivePrefix = {arXiv},
arxivId = {1810.02565},
author = {Orvieto, Antonio and Lucchi, Aurelien},
eprint = {1810.02565},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9424-continuous-time-models-for-stochastic-optimization-algorithms.pdf:pdf},
number = {NeurIPS},
title = {{Continuous-time Models for Stochastic Optimization Algorithms}},
url = {http://arxiv.org/abs/1810.02565},
year = {2018}
}
@article{Balghiti2019,
abstract = {The predict-then-optimize framework is fundamental in many practical settings: predict the unknown parameters of an optimization problem, and then solve the problem using the predicted values of the parameters. A natural loss function in this environment is to consider the cost of the decisions induced by the predicted parameters, in contrast to the prediction error of the parameters. This loss function was recently introduced in Elmachtoub and Grigas (2017), which called it the Smart Predict-then-Optimize (SPO) loss. Since the SPO loss is nonconvex and noncontinuous, standard results for deriving generalization bounds do not apply. In this work, we provide an assortment of generalization bounds for the SPO loss function. In particular, we derive bounds based on the Natarajan dimension that, in the case of a polyhedral feasible region, scale at most logarithmically in the number of extreme points, but, in the case of a general convex set, have poor dependence on the dimension. By exploiting the structure of the SPO loss function and an additional strong convexity assumption on the feasible region, we can dramatically improve the dependence on the dimension via an analysis and corresponding bounds that are akin to the margin guarantees in classification problems.},
archivePrefix = {arXiv},
arxivId = {1905.11488},
author = {Balghiti, Othman El and Elmachtoub, Adam N. and Grigas, Paul and Tewari, Ambuj},
eprint = {1905.11488},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9585-generalization-bounds-in-the-predict-then-optimize-framework.pdf:pdf},
number = {NeurIPS},
title = {{Generalization Bounds in the Predict-then-Optimize Framework}},
url = {http://arxiv.org/abs/1905.11488},
year = {2019}
}
@article{Salcedo-Sanz2016,
author = {Salcedo-Sanz, S},
doi = {10.1016/j.physrep.2016.08.001},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0370157316302332-main.pdf:pdf},
issn = {0370-1573},
journal = {Physics Reports},
keywords = {ga,optimization decision tree,pso,search and optimization},
mendeley-tags = {ga,optimization decision tree,pso},
pages = {1--70},
publisher = {Elsevier B.V.},
title = {{Modern meta-heuristics based on nonlinear physics processes : A review of models and design procedures}},
url = {http://dx.doi.org/10.1016/j.physrep.2016.08.001},
volume = {655},
year = {2016}
}
@article{BirattariM.PaqueteL.Stutzle,
author = {{Birattari, M., Paquete, L., St{\"{u}}tzle}, T.},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/AIDA-01-05.pdf:pdf},
journal = {Tech. Rep.},
keywords = {optimization decision tree},
mendeley-tags = {optimization decision tree},
title = {{Classification of Metaheuristics and Design of Experiments for the Analysis of Components}},
year = {2001}
}
@article{Andrychowicz2016,
abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
archivePrefix = {arXiv},
arxivId = {1606.04474},
author = {Andrychowicz, Marcin and Denil, Misha and Colmenarejo, Sergio G{\'{o}}mez and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and {De Freitas}, Nando},
eprint = {1606.04474},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1606.04474v1.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {3988--3996},
title = {{Learning to learn by gradient descent by gradient descent}},
year = {2016}
}
@article{Orvieto2019,
abstract = {Ordinary differential equation (ODE) models of gradient-based optimization methods can provide insights into the dynamics of learning and inspire the design of new algorithms. Unfortunately, this thought-provoking perspective is weakened by the fact that, in the worst case, the error between the algorithm steps and its ODE approximation grows exponentially with the number of iterations. In an attempt to encourage the use of continuous-time methods in optimization, we show that, if some additional regularity on the objective is assumed, the ODE representations of Gradient Descent and Heavy-ball do not suffer from the aforementioned problem, once we allow for a small perturbation on the algorithm initial condition. In the dynamical systems literature, this phenomenon is called shadowing. Our analysis relies on the concept of hyperbolicity, as well as on tools from numerical analysis.},
archivePrefix = {arXiv},
arxivId = {1911.05206},
author = {Orvieto, Antonio and Lucchi, Aurelien},
eprint = {1911.05206},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9431-shadowing-properties-of-optimization-algorithms.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{Shadowing Properties of Optimization Algorithms}},
url = {http://arxiv.org/abs/1911.05206},
year = {2019}
}
@article{Lyon2017,
abstract = {Tieleman, Tijmen and Hinton, Geoffrey. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012},
author = {Lyon, Richard F. and Lyon, Richard F.},
doi = {10.1017/9781139051699.031},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/lecture{\_}slides{\_}lec6.pdf:pdf},
journal = {Human and Machine Hearing},
pages = {419--440},
title = {{Neural Networks for Machine Learning}},
year = {2017}
}
@article{Wei2006,
abstract = {A modified variable string length genetic algorithm, called MVGA, is proposed for text clustering in this paper. Our algorithm has been exploited for automatically evolving the optimal number of clusters as well as providing proper data set clustering. The chromosome is encoded by special indices to indicate the location of each gene. More effective version of evolutional steps can automatically adjust the influence between the diversity of the population and selective pressure during generations. The superiority of the MVGA over conventional variable string length genetic algorithm (VGA) is demonstrated by providing proper text clustering. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
author = {Wei, Song and Soon, Cheol Park},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0031320399001375-main.pdf:pdf},
isbn = {3540459014},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {clustering metric,euclidean distance,ga,genetic algorithm,genetic algorithms,k -means algorithm,real encoding},
mendeley-tags = {ga,genetic algorithm},
pages = {779--782},
title = {{Genetic algorithm-based text clustering technique}},
volume = {4221 LNCS},
year = {2006}
}
@article{Powell2019,
abstract = {Stochastic optimization is an umbrella term that includes over a dozen fragmented communities, using a patchwork of sometimes overlapping notational systems with algorithmic strategies that are suited to specific classes of problems. This paper reviews the canonical models of these communities, and proposes a universal modeling framework that encompasses all of these competing approaches. At the heart is an objective function that optimizes over policies that is standard in some approaches, but foreign to others. We then identify four meta-classes of policies that encompasses all of the approaches that we have identified in the research literature or industry practice. In the process, we observe that any adaptive learning algorithm, whether it is derivative-based or derivative-free, is a form of policy that can be tuned to optimize either the cumulative reward (similar to multi-armed bandit problems) or final reward (as is used in ranking and selection or stochastic search). We argue that the principles of bandit problems, long a niche community, should become a core dimension of mainstream stochastic optimization.},
author = {Powell, Warren B.},
doi = {10.1016/j.ejor.2018.07.014},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0377221718306192-main.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Bandit problems,Dynamic programming,Reinforcement learning,Robust optimization,Simulation optimization,Stochastic programming,optimization decision tree},
mendeley-tags = {optimization decision tree},
number = {3},
pages = {795--821},
publisher = {Elsevier B.V.},
title = {{A unified framework for stochastic optimization}},
url = {https://doi.org/10.1016/j.ejor.2018.07.014},
volume = {275},
year = {2019}
}
@article{Joy2020,
abstract = {Hyperparameters are crucial to many machine learning algorithms. Conventional methods like grid search can be expensive when tuning hyperparameters of a complex model, for example, deep neural networks. Recently, Bayesian optimization has become popular in the machine learning community as an efficient tool for tuning hyperparameters. Bayesian optimization is a global optimization technique that is well suited for optimizing expensive black-box functions. Traditionally Bayesian optimization operates sequentially with one recommendation per trial. However, often a batch of recommendations can be simultaneously evaluated. Current batch Bayesian methods are mostly heuristic based and none have considered heteroscedastic nature of the unknown objective functions. This paper proposes a new batch Bayesian optimization method using a multi-scale search strategy. A batch of recommendations is constructed by searching for optimal recommendations across objective functions using alternate smoothness assumptions. Theoretical analysis shows that the proposed batch improves the regret bound of the sequential method by an order of K, where K is the batch size. We show the effectiveness of our techniques by minimizing three benchmark global optimization test functions and tuning the hyperparameters of two machine learning algorithms.},
author = {Joy, Tinu Theckel and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
doi = {10.1016/j.knosys.2019.06.026},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S095070511930293X-main.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Batch Bayesian optimization,Bayesian optimization,Gaussian process},
pages = {104818},
publisher = {Elsevier B.V.},
title = {{Batch Bayesian optimization using multi-scale search}},
url = {https://doi.org/10.1016/j.knosys.2019.06.026},
volume = {187},
year = {2020}
}
@article{Wolpert1997,
abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms. {\textcopyright} 1997 IEEE.},
author = {Wolpert, David H. and Macready, William G.},
doi = {10.1109/4235.585893},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/wolpert1997.pdf:pdf},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Evolutionary algorithms,Information theory,Optimization},
number = {1},
pages = {67--82},
title = {{No free lunch theorems for optimization}},
volume = {1},
year = {1997}
}
@article{Bessa2017,
abstract = {A new data-driven computational framework is developed to assist in the design and modeling of new material systems and structures. The proposed framework integrates three general steps: (1) design of experiments, where the input variables describing material geometry (microstructure), phase properties and external conditions are sampled; (2) efficient computational analyses of each design sample, leading to the creation of a material response database; and (3) machine learning applied to this database to obtain a new design or response model. In addition, the authors address the longstanding challenge of developing a data-driven approach applicable to problems that involve unacceptable computational expense when solved by standard analysis methods – e.g. finite element analysis of representative volume elements involving plasticity and damage. In these cases the framework includes the recently developed “self-consistent clustering analysis” method in order to build large databases suitable for machine learning. The authors believe that this will open new avenues to finding innovative materials with new capabilities in an era of high-throughput computing (“big-data”).},
author = {Bessa, M. A. and Bostanabad, R. and Liu, Z. and Hu, A. and Apley, Daniel W. and Brinson, C. and Chen, W. and Liu, Wing Kam},
doi = {10.1016/j.cma.2017.03.037},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/A{\_}framework{\_}for{\_}data-driven{\_}analysis{\_}of{\_}materials{\_}.pdf:pdf},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Design of experiments,Machine learning and data mining,Plasticity,Reduced order model,Self-consistent clustering analysis},
number = {April},
pages = {633--667},
title = {{A framework for data-driven analysis of materials under uncertainty: Countering the curse of dimensionality}},
volume = {320},
year = {2017}
}
@article{Eberhart1995,
abstract = {The optimization of nonlinear functions using particle swarm methodology is described. Implementations of two paradigms are discussed and compared, including a recently developed locally oriented paradigm. Benchmark testing of both paradigms is described, and applications, including neural network training and robot task learning, are proposed. Relationships between particle swarm optimization and both artificial life and evolutionary computation are reviewed.},
author = {Eberhart, Russell and Kennedy, James},
doi = {10.1109/mhs.1995.494215},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/PSO{\_}2.pdf:pdf},
isbn = {0780326768},
journal = {Proceedings of the International Symposium on Micro Machine and Human Science},
keywords = {particle swarm,pso},
mendeley-tags = {particle swarm,pso},
pages = {39--43},
title = {{New optimizer using particle swarm theory}},
year = {1995}
}
@article{Joshi2017,
abstract = {The Cuckoo Search algorithm is a recently developed meta-heuristic optimization algorithm, which is used for solving optimization problems. This is a nature-inspired metaheuristic algorithm, which is based on the brood parasitism of some cuckoo species, along with Levy flights random walks. Normally, the parameters of the cuckoo search are kept constant for certain duration, this results into decrease the efficiency of the algorithm. To make a deal with this issue, a proper strategy for tuning the cuckoo search parameters is to be defined. Cuckoos are fascinating birds, not only because of the beautiful sounds they can make but also because of their aggressive reproduction strategy. Some species such as the Ani and Guira cuckoos lay their eggs in host bird nest, and they may remove others eggs to increase the hatching probability of their own. In this paper, cuckoos behaviour {\&} their egg laying strategy in the nests of other host birds is explained.},
author = {Joshi, A. S. and Kulkarni, Omkar and Kakandikar, G. M. and Nandedkar, V. M.},
doi = {10.1016/j.matpr.2017.07.055},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S2214785317313433-main.pdf:pdf},
issn = {22147853},
journal = {Materials Today: Proceedings},
keywords = {Applications,Cuckoo Search Optimization,cs,cuckoo search},
mendeley-tags = {cs,cuckoo search},
number = {8},
pages = {7262--7269},
title = {{Cuckoo Search Optimization- A Review}},
url = {https://doi.org/10.1016/j.matpr.2017.07.055},
volume = {4},
year = {2017}
}
@inproceedings{Snoek2012,
abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes bruteforce search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
archivePrefix = {arXiv},
arxivId = {1206.2944},
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1206.2944},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
title = {{Practical Bayesian optimization of machine learning algorithms}},
year = {2012}
}
@book{Lauritzen2013,
abstract = {In many engineered systems, optimization is used for decision making at time-scales rang-ing from real-time operation to long-term plan-ning. This process often involves solving sim-ilar optimization problems over and over again with slightly modified input parameters, often under stringent time requirements. We consider the problem of using the information available through this solution process to directly learn the optimal solution as a function of the input parameters, thus reducing the need of solving computationally expensive large-scale paramet-ric programs in real time. Our proposed method is based on learning relevant sets of active con-straints, from which the optimal solution can be obtained efficiently. Using active sets as features preserves information about the physics of the system, enables more interpretable learning poli-cies, and inherently accounts for relevant safety constraints. Further, the number of relevant ac-tive sets is finite, which make them simpler ob-jects to learn. To learn the relevant active sets, we propose a streaming algorithm backed up by the-oretical results. Through extensive experiments on benchmarks of the Optimal Power Flow prob-lem, we observe that often only a few active sets are relevant in practice, suggesting that this is the appropriate level of abstraction for a learning al-gorithm to target.},
author = {Boyd, Stephan and Vandenberghe, Lieven},
booktitle = {Undergraduate Convexity},
doi = {10.1142/9789814412520_0010},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/bv{\_}cvxbook.pdf:pdf},
isbn = {9780521833783},
pages = {223--251},
title = {{Convex optimization}},
year = {2013}
}
@article{Perrone2019,
abstract = {Bayesian optimization (BO) is a successful methodology to optimize black-box functions that are expensive to evaluate. While traditional methods optimize each black-box function in isolation, there has been recent interest in speeding up BO by transferring knowledge across multiple related black-box functions. In this work, we introduce a method to automatically design the BO search space by relying on evaluations of previous black-box functions. We depart from the common practice of defining a set of arbitrary search ranges a priori by considering search space geometries that are learned from historical data. This simple, yet effective strategy can be used to endow many existing BO methods with transfer learning properties. Despite its simplicity, we show that our approach considerably boosts BO by reducing the size of the search space, thus accelerating the optimization of a variety of black-box optimization problems. In particular, the proposed approach combined with random search results in a parameter-free, easy-to-implement, robust hyperparameter optimization strategy. We hope it will constitute a natural baseline for further research attempting to warm-start BO.},
archivePrefix = {arXiv},
arxivId = {1909.12552},
author = {Perrone, Valerio and Shen, Huibin and Seeger, Matthias and Archambeau, Cedric and Jenatton, Rodolphe},
eprint = {1909.12552},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9438-learning-search-spaces-for-bayesian-optimization-another-view-of-hyperparameter-transfer-learning.pdf:pdf},
number = {NeurIPS},
title = {{Learning search spaces for Bayesian optimization: Another view of hyperparameter transfer learning}},
url = {http://arxiv.org/abs/1909.12552},
year = {2019}
}
@book{Rasmussen2006,
abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GP have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
author = {Rasmussen, Carl Edward and Williams, C K I},
booktitle = {The MIT Press, Cambridge, MA, USA},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/(Adaptive computation and machine learning) Carl Edward Rasmussen, Christopher K. I. Williams - Gaussian Processes for Machine Lea(2006).pdf:pdf},
isbn = {026218253X},
keywords = {1,bayesian inference,gaussian processes,gaussian processes in a,in this section,introduction and overview,kernel methods,nonparametric statistics,nutshell,reasoning be-,we introduce the basic},
number = {2},
pages = {715--719},
title = {{Gaussian processes for machine learning. 2006}},
volume = {38},
year = {2006}
}
@article{Kulunchakov2019,
abstract = {In this paper, we introduce various mechanisms to obtain accelerated first-order stochastic optimization algorithms when the objective function is convex or strongly convex. Specifically, we extend the Catalyst approach originally designed for deterministic objectives to the stochastic setting. Given an optimization method with mild convergence guarantees for strongly convex problems, the challenge is to accelerate convergence to a noise-dominated region, and then achieve convergence with an optimal worst-case complexity depending on the noise variance of the gradients. A side contribution of our work is also a generic analysis that can handle inexact proximal operators, providing new insights about the robustness of stochastic algorithms when the proximal operator cannot be exactly computed.},
archivePrefix = {arXiv},
arxivId = {1906.01164},
author = {Kulunchakov, Andrei and Mairal, Julien},
eprint = {1906.01164},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/9421-a-generic-acceleration-framework-for-stochastic-composite-optimization.pdf:pdf},
number = {NeurIPS},
pages = {1--12},
title = {{A Generic Acceleration Framework for Stochastic Composite Optimization}},
url = {http://arxiv.org/abs/1906.01164},
year = {2019}
}
@article{Lepretre2019,
abstract = {Finding optimal traffic light timings at road intersections is a mandatory step for urban planners wishing to achieve a sustainable mobility in modern cities. Increasing congestion situations constantly require urbanists to enhance traffic fluidity, while limiting pollutant emissions and vehicle consumption to improve inhabitants' welfare. Various mono or multi-objective optimization methods, such as evolutionary algorithms, fuzzy logic algorithms or even particle swarm optimizations, help to reach optimal traffic signal settings. However, those methods are usually designed to tackle very specific transportation configurations. Here, we introduce an extended version of the SIALAC benchmark, bringing together several real-world-like study cases with various features related to population, working activities, or traffic light devices. We drive a fitness landscape analysis on these various benchmark instances, which helps to improve the design of optimization algorithms for this class of real-world mobility problems. Thereby, we propose a new adaptive optimization algorithm to tackle each scenario of the benchmark.},
author = {Lepr{\^{e}}tre, Florian and Fonlupt, Cyril and Verel, S{\'{e}}bastien and Marion, Virginie and Armas, Rolando and Aguirre, Hern{\'{a}}n and Tanaka, Kiyoshi},
doi = {10.1016/j.asoc.2019.105869},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S1568494619306507-main.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing Journal},
keywords = {Benchmark,Fitness landscapes,Optimization,Real-world,Traffic lights},
pages = {105869},
publisher = {Elsevier B.V.},
title = {{Fitness landscapes analysis and adaptive algorithms design for traffic lights optimization on SIALAC benchmark}},
url = {https://doi.org/10.1016/j.asoc.2019.105869},
volume = {85},
year = {2019}
}
@article{Bre2020,
abstract = {Nowadays, performing multi-objective optimizations of actual building designs is one of the most challenging problems of the building energy efficiency area. This paper aims to propose an efficient method to solve multi-objective optimization building performance problems using a novel metamodel-based approach. To this end, the multi-objective Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is dynamically coupled with artificial neural network (ANN) metamodels, which were previously trained with results of building performance simulations conducted using the EnergyPlusTM software. This new approach proposes an optimal way to generate the samples used to train and validate the ANN-based metamodels minimizing the total of building energy simulations necessary to train them, and guarantees accurate optimization results. To validate the strengths of the proposed method, it is applied to optimize the energy efficiency and thermal comfort of an actual dwelling in order to get the best trade-off (Pareto front) of the building between heating and cooling performance. This case study involves 12 of the more influential discrete and categorical design variables like roof types, external and internal wall types, solar orientation, solar absorptance, size and type of windows, and the dimension of external window shadings of this house among others, making a complex building performance optimization problem with more than 108 possibilities to choose. Furthermore, the results obtained are systematically compared and validated with the “true” Pareto front achieved using a simulate-based scheme which directly couples EnergyPlus program and NSGA-II algorithm. Results indicated that the presented method is able to reduce up to 75{\%} the number of building energy simulations needed to find the Pareto front of an actual multi-objective building performance optimization problem, keeping a good accuracy of the results.},
author = {Bre, Facundo and Roman, Nadia and Fachinotti, V{\'{i}}ctor D.},
doi = {10.1016/j.enbuild.2019.109576},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/1-s2.0-S0378778819323047-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building performance optimization,Energy-efficient buildings,Metamodeling,Multi-objective optimization,Surrogate model},
pages = {109576},
publisher = {Elsevier B.V.},
title = {{An efficient metamodel-based method to carry out multi-objective building performance optimizations}},
url = {https://doi.org/10.1016/j.enbuild.2019.109576},
volume = {206},
year = {2020}
}
@article{Xu2015,
abstract = {In designing microstructural materials systems, one of the key research questions is how to represent the microstructural design space quantitatively using a descriptor set that is sufficient yet small enough to be tractable. Existing approaches describe complex microstructures either using a small set of descriptors that lack sufficient level of details, or using generic high order microstructure functions of infinite dimensionality without explicit physical meanings. We propose a new machine learning-based method for identifying the key microstructure descriptors from vast candidates as potential microstructural design variables. With a large number of candidate microstructure descriptors collected from literature covering a wide range of microstructural material systems, a four-step machine learning-based method is developed to eliminate redundant microstructure descriptors via image analyses, to identify key microstructure descriptors based on structure-property data, and to determine the microstructure design variables. The training criteria of the supervised learning process include both microstructure correlation functions and material properties. The proposed methodology effectively reduces the infinite dimension of the microstructure design space to a small set of descriptors without a significant information loss. The benefits are demonstrated by an example of polymer nanocomposites optimization. We compare designs using key microstructure descriptors versus using empirically chosen microstructure descriptors as a demonstration of the proposed method.},
author = {Xu, Hongyi and Liu, Ruoqian and Choudhary, Alok and Chen, Wei},
doi = {10.1115/1.4029768},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/e825310f2573344b2f907587e7288fd9899f.pdf:pdf},
issn = {10500472},
journal = {Journal of Mechanical Design, Transactions of the ASME},
keywords = {informatics,machine learning,material design,microstructure descriptors},
number = {5},
pages = {1--10},
title = {{A Machine Learning-Based Design Representation Method for Designing Heterogeneous Microstructures}},
volume = {137},
year = {2015}
}
@article{Mockus1994,
abstract = {In this paper a review of application of Bayesian approach to global and stochastic optimization of continuous multimodal functions is given. Advantages and disadvantages of Bayesian approach (average case analysis), comparing it with more usual minimax approach (worst case analysis) are discussed. New interactive version of software for global optimization is discussed. Practical multidimensional problems of global optimization are considered {\textcopyright} 1994 Kluwer Academic Publishers.},
author = {Mockus, Jonas},
doi = {10.1007/BF01099263},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/Mockus1994{\_}Article{\_}ApplicationOfBayesianApproachT.pdf:pdf},
issn = {09255001},
journal = {Journal of Global Optimization},
keywords = {Bayesian,Optimization,continuous,global,stochastic},
number = {4},
pages = {347--365},
title = {{Application of Bayesian approach to numerical methods of global and stochastic optimization}},
volume = {4},
year = {1994}
}
@article{Bessa2018,
abstract = {A data-driven computational framework combining Bayesian regression for imperfection-sensitive quantities of interest, uncertainty quantification and multi-objective optimization is developed for the design of complex structures. The framework is used to design ultra-thin carbon fiber deployable shells subjected to two bending conditions. Significant increases in the ultimate buckling loads are shown to be possible, with potential gains on the order of 100{\%} as compared to a previously proposed design. The key to this result is the existence of a large load reserve capability after the initial bifurcation point and well into the post-buckling range that can be effectively explored by the data-driven approach. The computational strategy here presented is general and can be applied to different problems in structural and materials design, with the potential of finding relevant designs within high-dimensional spaces.},
author = {Bessa, M. A. and Pellegrino, S.},
doi = {10.1016/j.ijsolstr.2018.01.035},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/Bessa{\_}ultrathin{\_}shell{\_}structures{\_}2018.pdf:pdf},
issn = {00207683},
journal = {International Journal of Solids and Structures},
keywords = {Buckling,Data mining,Design charts,Evolutionary optimization,Heteroscedastic Gaussian process,Post-buckling,Ultra-thin composites},
pages = {174--188},
title = {{Design of ultra-thin shell structures in the stochastic post-buckling range using Bayesian machine learning and optimization}},
volume = {139-140},
year = {2018}
}
@article{Blum2003,
abstract = {The field of metaheuristics for the application to combinatorial optimization problems is a rapidly growing field of research. This is due to the importance of combinatorial optimization problems for the scientific as well as the industrial world. We give a survey of the nowadays most important metaheuristics from a conceptual point of view. We outline the different components and concepts that are used in the different metaheuristics in order to analyze their similarities and differences. Two very important concepts in metaheuristics are intensification and diversification. These are the two forces that largely determine the behavior of a metaheuristic. They are in some way contrary but also complementary to each other. We introduce a framework, that we call the I{\&}D frame, in order to put different intensification and diversification components into relation with each other. Outlining the advantages and disadvantages of different metaheuristic approaches we conclude by pointing out the importance of hybridization of metaheuristics as well as the integration of metaheuristics and other methods for optimization.},
author = {Blum, Christian and Roli, Andrea},
doi = {10.1145/937503.937505},
file = {:C$\backslash$:/Users/mpvan/OneDrive/Documenten/Mendeley Desktop/937503.937505.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {Combinatorial optimization,Diversification,Intensification,Metaheuristics},
number = {3},
pages = {268--308},
title = {{Metaheuristics in Combinatorial Optimization: Overview and Conceptual Comparison}},
volume = {35},
year = {2003}
}

