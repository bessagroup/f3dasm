{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART 2B**: Under the hood of MFBO: multi-fidelity Gaussian process regression (MFGPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Juypter notebook contains more in-depth information on MFGPR and how it can be used in `F3DASM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import f3dasm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "fids = [0.5, 1.0]\n",
    "costs = [0.5, 1.0]\n",
    "samp_nos = [500, 10] # Explanation: [no. of low fidelity pts., no. of high fidelity pts.]\n",
    "\n",
    "noise_fix = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify the multi-fidelity problem\n",
    "In the part 1, the user employs `create_analytical_mf_problem` as a pipeline method to generate elements of a multi-fidelity problem based on analytical functions.\n",
    "\n",
    "Here, we go more in depth about what this feature does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a base function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_fun = f3dasm.functions.Periodic(\n",
    "    dimensionality=dim,\n",
    "    scale_bounds=np.tile([0.0, 1.0], (dim, 1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the list of augmented functions that constitute the multi-fidelity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funs = []\n",
    "for fid in fids:\n",
    "        fun = f3dasm.AugmentedFunction(\n",
    "                base_fun=base_fun,\n",
    "                fid=fid,\n",
    "                )\n",
    "\n",
    "        funs.append(fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the multi-fidelity design space is created as a list of augmentations of the design parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_design_space = []\n",
    "\n",
    "for fid in fids:\n",
    "    design = f3dasm.make_nd_continuous_design(\n",
    "        bounds=np.tile([0.0, 1.0], (dim, 1)),\n",
    "        dimensionality=dim,\n",
    "    )\n",
    "    fidelity_parameter = f3dasm.ConstantParameter(name=\"fid\", constant_value=fid)\n",
    "    design.add_input_space(fidelity_parameter)\n",
    "\n",
    "    mf_design_space.append(design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_design_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the fidelity-augmented design spaces then gives rise to a sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_sampler = []\n",
    "for design in mf_design_space:\n",
    "    \n",
    "    sampler = f3dasm.sampling.SobolSequence(design=design)\n",
    "    mf_sampler.append(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a DoE from each augmented design space is sampled, and subsequently combined into a multi-fidelity DoE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_train_data = []\n",
    "for sampler, fun,  samp_no in zip(mf_sampler, funs, samp_nos):\n",
    "    train_data = sampler.get_samples(numsamples=samp_no)\n",
    "\n",
    "    train_data.add_output(output=fun(train_data))    \n",
    "    \n",
    "    mf_train_data.append(train_data)\n",
    "\n",
    "mf_train_data[-1].data = pd.concat([d.data for d in mf_train_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_train_data[-1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A regressor object is built based on the (multi-fidelity) data and the design.\n",
    "\n",
    "This type of multi-fidelity Gaussian process regression is described in the following article:\n",
    "\n",
    "```{bibliography}\n",
    "Wu, J.; Toscano-Palmerin, S.; Frazier, P. I. & Wilson, A. G.\n",
    "Practical multi-fidelity bayesian optimization for hyperparameter tuning \n",
    "Uncertainty in Artificial Intelligence, 2020, 788-798\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = f3dasm.regression.gpr.Stmf(\n",
    "    mf_train_data=mf_train_data[-1],\n",
    "    mf_design=mf_train_data[-1].design,\n",
    "    noise_fix=noise_fix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting surrogate model is obtained by training the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = regressor.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This surrogate model can then be used to predict the (high-fidelity) output for any point in the design space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = f3dasm.sampling.LatinHypercube(design=mf_design_space[-1])\n",
    "test_data = test_sampler.get_samples(numsamples=500)\n",
    "\n",
    "mean, var = surrogate.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the prediction alongside the exact objective landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.add_output(mean)\n",
    "test_data_var = np.hstack((test_data.data.values, var))\n",
    "test_sort = test_data_var[test_data_var[:, 0].argsort()]\n",
    "\n",
    "ucb, lcb = [test_sort[:, 2] + 2 * (-1) ** k * np.sqrt(np.abs(test_sort[:, 3])) for k in range(2)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "hf_data = train_data.data.loc[train_data.data['input', 'fid'] == 1.]\n",
    "plt.scatter(hf_data['input', 'x0'], hf_data['output'], label='High fidelity data', c='b')\n",
    "plt.plot(test_sort[:, 0], test_sort[:, 2], color='purple', label='High fidelity prediction')\n",
    "plt.fill_between(test_sort[:, 0].flatten(), lcb, ucb, color='purple', alpha=.25, label='Confidence')\n",
    "plt.plot(test_sort[:, 0], base_fun(test_sort[:, 0][:, None]), 'b--', label='High fidelity exact')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exercises.\n",
    "1. Change the (base) function into the Schwefel function. What do you notice?\n",
    "2. Use `50` high-fidelity data points and `500` low-fidelity data points. Compare the result with the single-fidelity result with suggested hyperparameter settings of Exercise 3 in part A. What do you notice?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('f3dasm_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9d896b1e26959336e7f4be8af34f758934959c162bfe59669aabbaab50cee31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
