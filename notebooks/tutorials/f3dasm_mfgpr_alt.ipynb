{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A regressor object is built based on the (multi-fidelity) data and the design.\n",
    "\n",
    "This type of multi-fidelity Gaussian process regression is described in the following article:\n",
    "\n",
    "```{bibliography}\n",
    "Wu, J.; Toscano-Palmerin, S.; Frazier, P. I. & Wilson, A. G.\n",
    "Practical multi-fidelity bayesian optimization for hyperparameter tuning \n",
    "Uncertainty in Artificial Intelligence, 2020, 788-798\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = f3dasm.regression.gpr.Stmf(\n",
    "    mf_train_data=mf_train_data[-1],\n",
    "    mf_design=mf_train_data[-1].design,\n",
    "    noise_fix=noise_fix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting surrogate model is obtained by training the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = regressor.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This surrogate model can then be used to predict the (high-fidelity) output for any point in the design space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = f3dasm.sampling.LatinHypercube(design=mf_design_space[-1])\n",
    "test_data = test_sampler.get_samples(numsamples=500)\n",
    "\n",
    "mean, var = surrogate.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the prediction alongside the exact objective landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.add_output(mean)\n",
    "test_data_var = np.hstack((test_data.data.values, var))\n",
    "test_sort = test_data_var[test_data_var[:, 0].argsort()]\n",
    "\n",
    "ucb, lcb = [test_sort[:, 2] + 2 * (-1) ** k * np.sqrt(np.abs(test_sort[:, 3])) for k in range(2)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "hf_data = train_data.data.loc[train_data.data['input', 'fid'] == 1.]\n",
    "plt.scatter(hf_data['input', 'x0'], hf_data['output'], label='High fidelity data', c='b')\n",
    "plt.plot(test_sort[:, 0], test_sort[:, 2], color='purple', label='High fidelity prediction')\n",
    "plt.fill_between(test_sort[:, 0].flatten(), lcb, ucb, color='purple', alpha=.25, label='Confidence')\n",
    "plt.plot(test_sort[:, 0], base_fun(test_sort[:, 0][:, None]), 'b--', label='High fidelity exact')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f3dasm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9d896b1e26959336e7f4be8af34f758934959c162bfe59669aabbaab50cee31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
