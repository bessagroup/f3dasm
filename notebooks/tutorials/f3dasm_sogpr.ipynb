{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  **PART 2A**: The basics: Gaussian process regression in F3DASM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step-by-step tutorial with exercises can be followedin order to gain understanding of how regression works in F3DASM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import f3dasm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dimensionality = 1\n",
    "numsamples = 10\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(base_kernel=gpytorch.kernels.RBFKernel())\n",
    "\n",
    "noise_fix = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = f3dasm.functions.Levy(\n",
    "    dimensionality=dimensionality,\n",
    "    scale_bounds=np.tile([0.0, 1.0], (dimensionality, 1)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_plot = np.linspace(0, 1, 500)[:, None] # add 1D plot method for functions!\n",
    "y_plot = fun(x_plot)\n",
    "\n",
    "# y_plot = (y_plot - np.mean(y_plot)) / np.std(y_plot)\n",
    "\n",
    "plt.plot(x_plot, y_plot, 'b--', label='Exact')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Add the design space, sampler and finally the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parameter_DesignSpace: f3dasm.DesignSpace = f3dasm.make_nd_continuous_design(\n",
    "    bounds=np.tile([0.0, 1.0], (dimensionality, 1)),\n",
    "    dimensionality=dimensionality,\n",
    ")\n",
    "\n",
    "sampler = f3dasm.sampling.SobolSequence(design=parameter_DesignSpace)\n",
    "\n",
    "train_data: f3dasm.Data = sampler.get_samples(numsamples=numsamples)\n",
    "train_data.add_output(output=fun(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how the training data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unscaled = train_data.get_output_data()\n",
    "y_scaled = (y_unscaled - np.mean(y_unscaled)) / np.std(y_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.data['output'] = y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_plot, y_plot, 'b--', label='Exact')\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Regression and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param = f3dasm.regression.gpr.Sogpr_Parameters(kernel=kernel)\n",
    "\n",
    "regressor = f3dasm.regression.gpr.Sogpr(\n",
    "    train_data=train_data, \n",
    "    design=train_data.design,\n",
    "    parameter=param,\n",
    "    noise_fix=noise_fix,\n",
    ")\n",
    "\n",
    "surrogate = regressor.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# surrogate.model.likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=torch.tensor([0.1]))\n",
    "\n",
    "# cons = gpytorch.constraints.constraints.GreaterThan(1e-0)\n",
    "# surrogate.model.likelihood.noise_covar.register_constraint(\"raw_noise\", cons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's evaluate the mean and the variance of the Gaussian process posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_plot_data = f3dasm.Data(design=train_data.design)\n",
    "x_plot_data.add_numpy_arrays(input=x_plot, output=x_plot)\n",
    "mean, var = surrogate.predict(test_input_data=x_plot_data)\n",
    "\n",
    "ucb, lcb = [mean + 2 * (-1) ** k * np.sqrt(np.abs(var)) for k in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how the prediction looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_plot, y_plot, 'b--', label='Exact') # add regression plot\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.plot(x_plot, mean, color='purple', label='Prediction')\n",
    "plt.fill_between(x_plot.flatten(), lcb.flatten(), ucb.flatten(), color='purple', alpha=.25, label='Confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.model.covar_module.raw_outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.model.covar_module.base_kernel.raw_lengthscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing GPR results with other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process\n",
    "\n",
    "kernel_sklearn = sklearn.gaussian_process.kernels.ConstantKernel() * sklearn.gaussian_process.kernels.RBF()\n",
    "regressor_sklearn = sklearn.gaussian_process.GaussianProcessRegressor(kernel=kernel_sklearn, n_restarts_optimizer=10,)\n",
    "surrogate_sklearn = regressor_sklearn.fit(X=train_data.get_input_data(), y=train_data.get_output_data())\n",
    "mean_sklearn, std_sklearn = surrogate_sklearn.predict(X=x_plot, return_std=True)\n",
    "\n",
    "ucb_sklearn, lcb_sklearn = [mean_sklearn + 2 * (-1) ** k * std_sklearn for k in range(2)]\n",
    "\n",
    "plt.plot(x_plot, y_plot, 'b--', label='Exact') # add regression plot\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.plot(x_plot, mean_sklearn, color='purple', label='Prediction')\n",
    "plt.fill_between(x_plot.flatten(), lcb_sklearn.flatten(), ucb_sklearn.flatten(), color='purple', alpha=.25, label='Confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_sklearn.kernel_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "\n",
    "# kernel_gpy = GPy.kern.RBF()\n",
    "regressor_gpy = GPy.models.GPRegression(X=train_data.get_input_data(), Y=train_data.get_output_data(), kernel=None)\n",
    "regressor_gpy.Gaussian_noise.variance.fix(0)\n",
    "\n",
    "# regressor_gpy.optimize()\n",
    "regressor_gpy.optimize_restarts(num_restarts=10)\n",
    "surrogate_gpy = regressor_gpy\n",
    "\n",
    "mean_gpy, var_gpy = surrogate_gpy.predict(Xnew=x_plot)\n",
    "\n",
    "ucb_gpy, lcb_gpy = [mean_gpy + 2 * (-1) ** k * np.sqrt(np.abs(var_gpy)) for k in range(2)]\n",
    "\n",
    "plt.plot(x_plot, y_plot, 'b--', label='Exact') # add regression plot\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.plot(x_plot, mean_gpy, color='purple', label='Prediction')\n",
    "plt.fill_between(x_plot.flatten(), lcb_gpy.flatten(), ucb_gpy.flatten(), color='purple', alpha=.25, label='Confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_gpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Change the cosine GP kernel into an RBF kernel (`gpytorch.kernels.RBFKernel()`). What do you notice?\n",
    "2. Change the function to regress from the AlpineN2 into the Schwefel function (`f3dasm.functions.Schwefel`). What do you notice?\n",
    "3. Change the number of data points from `15` into a higher number $\\le$`150`. Does the GP regress well?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('f3dasm_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9d896b1e26959336e7f4be8af34f758934959c162bfe59669aabbaab50cee31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
