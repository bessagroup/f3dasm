{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  **PART 2A**: The basics: Gaussian process regression in F3DASM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step-by-step tutorial with exercises can be followedin order to gain understanding of how regression works in F3DASM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import f3dasm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dimensionality = 1\n",
    "numsamples = 5\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(base_kernel=gpytorch.kernels.RBFKernel())\n",
    "\n",
    "noise_fix = True\n",
    "max_retries = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = f3dasm.functions.Sphere(\n",
    "    dimensionality=dimensionality,\n",
    "    scale_bounds=np.tile([0.0, 1.0], (dimensionality, 1)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_plot = np.linspace(0, 1, 500)[:, None] # add 1D plot method for functions!\n",
    "y_plot = fun(x_plot)\n",
    "\n",
    "# y_plot = (y_plot - np.mean(y_plot)) / np.std(y_plot)\n",
    "\n",
    "plt.plot(x_plot, y_plot, 'b--', label='Exact')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Add the design space, sampler and finally the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parameter_DesignSpace: f3dasm.DesignSpace = f3dasm.make_nd_continuous_design(\n",
    "    bounds=np.tile([0.0, 1.0], (dimensionality, 1)),\n",
    "    dimensionality=dimensionality,\n",
    ")\n",
    "\n",
    "sampler = f3dasm.sampling.SobolSequence(design=parameter_DesignSpace, seed=123)\n",
    "\n",
    "train_data: f3dasm.Data = sampler.get_samples(numsamples=numsamples)\n",
    "train_data.add_output(output=fun(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how the training data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unscaled = train_data.get_output_data()\n",
    "y_scaled = (y_unscaled - np.mean(y_unscaled)) / np.std(y_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.data['output'] = y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_plot, y_plot, 'b--', label='Exact')\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Regression and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param = f3dasm.regression.gpr.Sogpr_Parameters(kernel=kernel)\n",
    "\n",
    "regressor = f3dasm.regression.gpr.Sogpr(\n",
    "    train_data=train_data, \n",
    "    design=train_data.design,\n",
    "    parameter=param,\n",
    "    noise_fix=noise_fix,\n",
    "    # noise_fix=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = regressor.train(optimize=True, max_retries=max_retries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate.model.likelihood.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# surrogate.model.covar_module.raw_outputscale = torch.nn.Parameter(torch.tensor(1.))\n",
    "# surrogate.model.covar_module.base_kernel.raw_lengthscale = torch.nn.Parameter(torch.tensor([[1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cons = gpytorch.constraints.constraints.Interval(1e-5, 1e5)\n",
    "# surrogate.model.covar_module.base_kernel.register_constraint(\"raw_lengthscale\", cons)\n",
    "# surrogate.model.covar_module.register_constraint(\"raw_outputscale\", cons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's evaluate the mean and the variance of the Gaussian process posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_plot_data = f3dasm.Data(design=train_data.design)\n",
    "x_plot_data.add_numpy_arrays(input=x_plot, output=x_plot)\n",
    "pred_mean, pred_var = surrogate.predict(test_input_data=x_plot_data)\n",
    "\n",
    "ucb, lcb = [pred_mean + 2 * (-1) ** k * np.sqrt(np.abs(pred_var)) for k in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how the prediction looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_plot, y_plot, 'b--', label='Exact') # add regression plot\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.plot(x_plot, pred_mean, color='purple', label='Prediction')\n",
    "plt.fill_between(x_plot.flatten(), lcb.flatten(), ucb.flatten(), color='purple', alpha=.25, label='Confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.model.covar_module.base_kernel.lengthscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the marginal log likelihood look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "likelihood = surrogate.model.likelihood\n",
    "model = surrogate.model\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# opt_pars = []\n",
    "# for _, value in list(model.named_parameters()):\n",
    "#     opt_par = torch.exp(torch.tensor(value.item()))\n",
    "#     print(_, opt_par)\n",
    "#     opt_pars.append(opt_par)\n",
    "\n",
    "opt_pars = [\n",
    "    torch.tensor(surrogate.model.likelihood.noise.item()),\n",
    "    torch.tensor(surrogate.model.covar_module.outputscale.item()),\n",
    "    torch.tensor(surrogate.model.covar_module.base_kernel.lengthscale.item())\n",
    "    ]\n",
    "\n",
    "print(opt_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = torch.logspace(torch.log10(opt_pars[0]) - 0.1, torch.log10(opt_pars[0]) + 0.1, steps=30)\n",
    "amp_scale = torch.logspace(torch.log10(opt_pars[1]) - 0.2, torch.log10(opt_pars[1]) + 0.2, steps=30)\n",
    "length_scale = torch.logspace(torch.log10(opt_pars[2]) - 0.2, torch.log10(opt_pars[2]) + 0.2, steps=30)\n",
    "\n",
    "# length_scale_grid, noise_scale_grid = torch.meshgrid(length_scale, noise_level)\n",
    "length_scale_grid, amp_scale_grid = torch.meshgrid(length_scale, amp_scale)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "mll_plot_list = []\n",
    "# for scale, noise in zip(length_scale_grid.ravel(), noise_scale_grid.ravel()):\n",
    "for scale, amp in zip(length_scale_grid.ravel(), amp_scale_grid.ravel()):\n",
    "    model.covar_module.base_kernel.lengthscale = scale\n",
    "    # model.likelihood.noise = noise\n",
    "    model.covar_module.outputscale = amp\n",
    "    mll_plot_list.append(\n",
    "        mll(\n",
    "        surrogate.model(torch.tensor(train_data.get_input_data().to_numpy().flatten())),\n",
    "        torch.tensor(train_data.get_output_data().to_numpy().flatten())\n",
    "        )\n",
    "    )\n",
    "\n",
    "mll_plot = torch.tensor(mll_plot_list).reshape(length_scale_grid.shape)\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "plt.figure()\n",
    "plt.contour(\n",
    "    length_scale_grid.numpy(),\n",
    "    # noise_scale_grid.numpy(),\n",
    "    amp_scale_grid.numpy(),\n",
    "    -mll_plot.numpy(),\n",
    "    levels=250,\n",
    "    # norm=LogNorm(vmin=vmin, vmax=vmax),\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Length-scale\")\n",
    "# plt.ylabel(\"Noise-level\")\n",
    "plt.ylabel(\"Output-scale\")\n",
    "plt.title(\"Log-marginal-likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metrics\n",
    "\n",
    "How well does this surrogate model perform?\n",
    "\n",
    "Let us calculate some error metrics, starting with the $L^1$, $L^2$ and $L^{\\infty}$ distances. Recall that the $L^p$ distance between two vectors $y,y'\\in\\mathbb{R}^n$ is defined as\n",
    "$$\\|y-y'\\|_{L^p}=\\left(\\sum_{k=1}^n|y_k-y_k'|^p\\right)^{1/p}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_norm = np.linalg.norm(y_plot - pred_mean, ord=1)\n",
    "l2_norm = np.linalg.norm(y_plot - pred_mean, ord=2)\n",
    "max_norm = np.linalg.norm(y_plot - pred_mean, ord=np.inf)\n",
    "\n",
    "l1_norm, l2_norm, max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are closely related to the mean squared error (MSE) and mean average error (MAE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = l1_norm / len(y_plot)\n",
    "MSE = l2_norm ** 2 / len(y_plot)\n",
    "\n",
    "MAE, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these values are commonly used as error metrics, something more robust is needed to apply to objective functions with varying sizes of the output range. This motivates scaling the metrics with the output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing GPR results with other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process\n",
    "\n",
    "kernel_sklearn = sklearn.gaussian_process.kernels.ConstantKernel() * sklearn.gaussian_process.kernels.RBF()\n",
    "regressor_sklearn = sklearn.gaussian_process.GaussianProcessRegressor(kernel=kernel_sklearn, n_restarts_optimizer=max_retries,)\n",
    "surrogate_sklearn = regressor_sklearn.fit(X=train_data.get_input_data(), y=train_data.get_output_data())\n",
    "mean_sklearn, std_sklearn = surrogate_sklearn.predict(X=x_plot, return_std=True)\n",
    "\n",
    "ucb_sklearn, lcb_sklearn = [mean_sklearn + 2 * (-1) ** k * std_sklearn for k in range(2)]\n",
    "\n",
    "plt.plot(x_plot, y_plot, 'b--', label='Exact') # add regression plot\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.plot(x_plot, mean_sklearn, color='purple', label='Prediction')\n",
    "plt.fill_between(x_plot.flatten(), lcb_sklearn.flatten(), ucb_sklearn.flatten(), color='purple', alpha=.25, label='Confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_sklearn.kernel_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "\n",
    "# kernel_gpy = GPy.kern.RBF()\n",
    "regressor_gpy = GPy.models.GPRegression(X=train_data.get_input_data(), Y=train_data.get_output_data(), normalizer=True, kernel=None)\n",
    "regressor_gpy.Gaussian_noise.variance.fix(0)\n",
    "\n",
    "regressor_gpy.optimize()\n",
    "# regressor_gpy.optimize_restarts(num_restarts=15)\n",
    "surrogate_gpy = regressor_gpy\n",
    "\n",
    "mean_gpy, var_gpy = surrogate_gpy.predict(Xnew=x_plot)\n",
    "\n",
    "ucb_gpy, lcb_gpy = [mean_gpy + 2 * (-1) ** k * np.sqrt(np.abs(var_gpy)) for k in range(2)]\n",
    "\n",
    "plt.plot(x_plot, y_plot, 'b--', label='Exact') # add regression plot\n",
    "plt.scatter(train_data.data['input'], train_data.data['output'], c='b', label='Training data')\n",
    "plt.plot(x_plot, mean_gpy, color='purple', label='Prediction')\n",
    "plt.fill_between(x_plot.flatten(), lcb_gpy.flatten(), ucb_gpy.flatten(), color='purple', alpha=.25, label='Confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.model.covar_module.base_kernel.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_sklearn.kernel_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_gpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Change the cosine GP kernel into an RBF kernel (`gpytorch.kernels.RBFKernel()`). What do you notice?\n",
    "2. Change the function to regress from the AlpineN2 into the Schwefel function (`f3dasm.functions.Schwefel`). What do you notice?\n",
    "3. Change the number of data points from `15` into a higher number $\\le$`150`. Does the GP regress well?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('f3dasm_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:36:39) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9d896b1e26959336e7f4be8af34f758934959c162bfe59669aabbaab50cee31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
